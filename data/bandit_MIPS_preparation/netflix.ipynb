{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 shape: (24058263, 2)\n",
      "-Dataset examples-\n",
      "    Cust_Id  Rating\n",
      "0        1:     NaN\n",
      "1   1488844     3.0\n",
      "2    822109     5.0\n",
      "3    885013     4.0\n",
      "4     30878     4.0\n",
      "..      ...     ...\n",
      "95  1245406     4.0\n",
      "96  1834590     3.0\n",
      "97   593225     3.0\n",
      "98  1011918     4.0\n",
      "99  1665054     4.0\n",
      "\n",
      "[100 rows x 2 columns]\n",
      "Movie numpy: [1.000e+00 1.000e+00 1.000e+00 ... 4.499e+03 4.499e+03 4.499e+03]\n",
      "Length: 24053764\n",
      "-Dataset examples-\n",
      "          Cust_Id  Rating  Movie_Id\n",
      "1         1488844     3.0         1\n",
      "5000996    501954     2.0       996\n",
      "10001962   404654     5.0      1962\n",
      "15002876   886608     2.0      2876\n",
      "20003825  1193835     2.0      3825\n",
      "Movie minimum times of review: 1799.0\n",
      "Customer minimum times of review: 52.0\n",
      "Original Shape: (24053764, 3)\n",
      "After Trim Shape: (17337458, 3)\n",
      "-Data Examples-\n",
      "          Cust_Id  Rating  Movie_Id\n",
      "696        712664     5.0         3\n",
      "6932490   1299309     5.0      1384\n",
      "13860273   400155     3.0      2660\n",
      "20766530   466962     4.0      3923\n",
      "start fitting\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "end fitting\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from surprise import Reader, Dataset\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVD, NMF\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "\n",
    "def main1():\n",
    "    # Follow the codes from Kaggle, see https://www.kaggle.com/datasets/netflix-inc/netflix-prize-data\n",
    "    filename = \"/Users/viraj/Documents/GitHub/MIPS/data\"\n",
    "    filename = os.path.join(filename, \"netflix_price_dataset/combined_data_1.txt\")\n",
    "    df = pd.read_csv(filename, header=None, names=['Cust_Id', 'Rating'], usecols=[0, 1])\n",
    "\n",
    "    df['Rating'] = df['Rating'].astype(float)\n",
    "\n",
    "    print('Dataset 1 shape: {}'.format(df.shape))\n",
    "    print('-Dataset examples-')\n",
    "    print(df.iloc[:100, :])\n",
    "\n",
    "    df_nan = pd.DataFrame(pd.isnull(df.Rating))\n",
    "    df_nan = df_nan[df_nan['Rating'] == True]\n",
    "    df_nan = df_nan.reset_index()\n",
    "\n",
    "    movie_np = []\n",
    "    movie_id = 1\n",
    "\n",
    "    for i, j in zip(df_nan['index'][1:], df_nan['index'][:-1]):\n",
    "        # numpy approach\n",
    "        temp = np.full((1, i - j - 1), movie_id)\n",
    "        movie_np = np.append(movie_np, temp)\n",
    "        movie_id += 1\n",
    "\n",
    "    # Account for last record and corresponding length\n",
    "    # numpy approach\n",
    "    last_record = np.full((1, len(df) - df_nan.iloc[-1, 0] - 1), movie_id)\n",
    "    movie_np = np.append(movie_np, last_record)\n",
    "\n",
    "    print('Movie numpy: {}'.format(movie_np))\n",
    "    print('Length: {}'.format(len(movie_np)))\n",
    "\n",
    "    # remove those Movie ID rows\n",
    "    df = df[pd.notnull(df['Rating'])]\n",
    "\n",
    "    df['Movie_Id'] = movie_np.astype(int)\n",
    "    df['Cust_Id'] = df['Cust_Id'].astype(int)\n",
    "    print('-Dataset examples-')\n",
    "    print(df.iloc[::5000000, :])\n",
    "\n",
    "    f = ['count', 'mean']\n",
    "\n",
    "    df_movie_summary = df.groupby('Movie_Id')['Rating'].agg(f)\n",
    "    df_movie_summary.index = df_movie_summary.index.map(int)\n",
    "    movie_benchmark = round(df_movie_summary['count'].quantile(0.7), 0)\n",
    "    drop_movie_list = df_movie_summary[df_movie_summary['count'] < movie_benchmark].index\n",
    "\n",
    "    print('Movie minimum times of review: {}'.format(movie_benchmark))\n",
    "\n",
    "    df_cust_summary = df.groupby('Cust_Id')['Rating'].agg(f)\n",
    "    df_cust_summary.index = df_cust_summary.index.map(int)\n",
    "    cust_benchmark = round(df_cust_summary['count'].quantile(0.7), 0)\n",
    "    drop_cust_list = df_cust_summary[df_cust_summary['count'] < cust_benchmark].index\n",
    "\n",
    "    print('Customer minimum times of review: {}'.format(cust_benchmark))\n",
    "\n",
    "    print('Original Shape: {}'.format(df.shape))\n",
    "    df = df[~df['Movie_Id'].isin(drop_movie_list)]\n",
    "    df = df[~df['Cust_Id'].isin(drop_cust_list)]\n",
    "    print('After Trim Shape: {}'.format(df.shape))\n",
    "    print('-Data Examples-')\n",
    "    print(df.iloc[::5000000, :])\n",
    "    df.to_csv(\"./netflix_cleaned1.csv\")\n",
    "\n",
    "    # Fit SVD model and store arrays\n",
    "    df = pd.read_csv(\"./netflix_cleaned1.csv\")\n",
    "    reader = Reader()\n",
    "    data = Dataset.load_from_df(df[['Movie_Id', 'Cust_Id', 'Rating']][:], reader)\n",
    "    trainset = data.build_full_trainset()\n",
    "    model = SVD(verbose=True)\n",
    "\n",
    "    print(\"start fitting\")\n",
    "    model.fit(trainset=trainset)\n",
    "\n",
    "    cur_dir = os.getcwd()\n",
    "    np.save(os.path.join(cur_dir, \"Movie_factors_15_new.npy\"), model.pu)\n",
    "    np.save(os.path.join(cur_dir, \"Movie_biases_15_new.npy\"), model.bu)\n",
    "    np.save(os.path.join(cur_dir, \"Customer_factors_15_new.npy\"), model.qi)\n",
    "    np.save(os.path.join(cur_dir, \"Customer_biases_15_new.npy\"), model.bi)\n",
    "    np.save(os.path.join(cur_dir, \"netflix_global_mean.npy\"), trainset.global_mean)\n",
    "    print(\"end fitting\")\n",
    "\n",
    "\n",
    "# def main2(filename: str = \"Movie_ratings\"):\n",
    "#     cur_dir = os.path.dirname(__file__)\n",
    "#     movie_factors = np.load(os.path.join(cur_dir, \"Movie_factors_15_new.npy\"))\n",
    "#     customer_factors = np.load(os.path.join(cur_dir, \"Customer_factors_15_new.npy\"))\n",
    "#     movie_biases = np.load(os.path.join(cur_dir, \"Movie_biases_15_new.npy\"))\n",
    "#     customer_biases = np.load(os.path.join(cur_dir, \"Customer_biases_15_new.npy\"))\n",
    "#     global_mean = np.load(os.path.join(cur_dir, \"netflix_global_mean.npy\"))\n",
    "\n",
    "#     data = movie_factors @ (customer_factors.transpose())\n",
    "#     data += np.expand_dims(movie_biases, axis=1)\n",
    "#     data += + np.expand_dims(customer_biases, axis=0)\n",
    "#     data += global_mean\n",
    "\n",
    "#     filename = os.path.join(cur_dir, f\"{filename}.npy\")\n",
    "#     np.save(filename, data)\n",
    "#     print(\"Store Movie ratings matrix.\")\n",
    "\n",
    "# def preprocess_netflix():\n",
    "#     main1()\n",
    "#     main2()\n",
    "\n",
    "\n",
    "main1()\n",
    "    # main2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main2(filename: str = \"movie_ratings\"):\n",
    "    cur_dir = os.getcwd()\n",
    "    movie_factors = np.load(os.path.join(cur_dir, \"Movie_factors_15_new.npy\"))\n",
    "    customer_factors = np.load(os.path.join(cur_dir, \"Customer_factors_15_new.npy\"))\n",
    "    movie_biases = np.load(os.path.join(cur_dir, \"Movie_biases_15_new.npy\"))\n",
    "    customer_biases = np.load(os.path.join(cur_dir, \"Customer_biases_15_new.npy\"))\n",
    "    global_mean = np.load(os.path.join(cur_dir, \"netflix_global_mean.npy\"))\n",
    "\n",
    "    data = movie_factors @ (customer_factors.transpose())\n",
    "    data += np.expand_dims(movie_biases, axis=1)\n",
    "    data += + np.expand_dims(customer_biases, axis=0)\n",
    "    data += global_mean\n",
    "\n",
    "    filename = os.path.join(cur_dir, f\"{filename}.npy\")\n",
    "    np.save(filename, data)\n",
    "    print(\"Store Movie ratings matrix.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store Movie ratings matrix.\n"
     ]
    }
   ],
   "source": [
    "main2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1350, 143458)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrs = np.load(\"/Users/viraj/Documents/GitHub/MIPS/data/mycode/movie_ratings.npy\")\n",
    "mrs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.18893675 3.93804694 2.97514296 ... 3.18208193 4.36759985 3.24433438]\n",
      " [3.17614068 3.37901069 2.59002104 ... 3.75228953 4.03185533 3.03243201]\n",
      " [3.2751007  2.71377304 2.4602786  ... 3.41542816 4.03894965 2.72822557]\n",
      " ...\n",
      " [2.36836285 2.23062555 2.04701642 ... 2.30244241 3.20041651 2.17102392]\n",
      " [3.34384158 3.10011515 2.33264784 ... 3.27898624 3.83039137 2.69163333]\n",
      " [4.21737977 3.81649531 3.04032904 ... 3.68071161 4.49925659 3.3437908 ]]\n"
     ]
    }
   ],
   "source": [
    "print(mrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
