{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from algorithms.greedy_mips import generate_conditer, greedy_mips  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess time: 0.0\n",
      "query dependent preprocess + candidates screening: 3.3665082454681396\n",
      "candidate ranking: 0.0\n",
      "Best 5 atoms (indices) for each signal:\n",
      "[[31  7 26 73 12]]\n",
      "Query-dependent runtime (seconds):\n",
      "[3.36650825]\n",
      "Candidate ranking runtime (seconds):\n",
      "[0.]\n",
      "Total complexities:\n",
      "[3430]\n",
      "Top 5 candidates using naive approach (indices): [21 33 27 38 45]\n",
      "Accuracy compared to naive method: 0.00%\n",
      "Speedup ratio: 1.46 times faster than naive computation.\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic test data\n",
    "def generate_test_data(num_atoms, len_signal):\n",
    "    \"\"\"\n",
    "    Generate random test data for atoms and signal vectors.\n",
    "    :param num_atoms: Number of atoms (data points)\n",
    "    :param len_signal: Length of each vector\n",
    "    :return: Tuple of atoms and signals\n",
    "    \"\"\"\n",
    "    np.random.seed(42)  # Set random seed for reproducibility\n",
    "    atoms = np.random.randn(num_atoms, len_signal)\n",
    "    signals = np.random.randn(1, len_signal)  # Single signal\n",
    "    return atoms, signals\n",
    "\n",
    "# Parameters for testing\n",
    "num_atoms = 100  # Number of atoms\n",
    "len_signal = 50  # Length of each vector\n",
    "atoms, signals = generate_test_data(num_atoms, len_signal)\n",
    "\n",
    "# Generate conditer for query-independent preprocessing\n",
    "conditer = generate_conditer(atoms)\n",
    "\n",
    "# Run Greedy MIPS\n",
    "budget = 10  # Number of atoms for naive computation\n",
    "num_best_atoms = 5  # Number of top atoms to retrieve\n",
    "best_atoms, query_times, ranking_times, complexities = greedy_mips(\n",
    "    atoms=atoms,\n",
    "    signals=signals,\n",
    "    budget=budget,\n",
    "    num_best_atoms=num_best_atoms,\n",
    "    conditer=conditer,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Output results\n",
    "print(f\"Best {num_best_atoms} atoms (indices) for each signal:\\n{best_atoms}\")\n",
    "print(f\"Query-dependent runtime (seconds):\\n{query_times}\")\n",
    "print(f\"Candidate ranking runtime (seconds):\\n{ranking_times}\")\n",
    "print(f\"Total complexities:\\n{complexities}\")\n",
    "\n",
    "# Naive approach for validation\n",
    "inner_products = np.dot(atoms, signals[0])\n",
    "top_k_naive = np.argsort(inner_products)[-num_best_atoms:][::-1]\n",
    "print(f\"Top {num_best_atoms} candidates using naive approach (indices): {top_k_naive}\")\n",
    "\n",
    "# Compare accuracy\n",
    "accuracy = len(np.intersect1d(best_atoms[0], top_k_naive)) / num_best_atoms\n",
    "print(f\"Accuracy compared to naive method: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Compute speedup\n",
    "total_naive_computations = num_atoms * len_signal * len(signals)\n",
    "average_complexity = complexities.mean()\n",
    "speedup_ratio = total_naive_computations / average_complexity\n",
    "print(f\"Speedup ratio: {speedup_ratio:.2f} times faster than naive computation.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movie Lens 100k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess time: 0.0\n",
      "query dependent preprocess + candidates screening: 0.0009822845458984375\n",
      "candidate ranking: 0.0\n",
      "Top 10 candidates (indices):\n",
      "[ 20  33 225  22  66 287 101 185 169 414]\n",
      "Query-dependent runtime (seconds): 0.0010\n",
      "Candidate ranking runtime (seconds): 0.0000\n",
      "Total complexity: 3430\n",
      "Top 10 candidates using naive approach (indices): [ 20  33 225  22  66  73 287 101 351 112]\n",
      "Accuracy compared to naive method: 70.00%\n",
      "Speedup ratio: 24.10 times faster than naive computation.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Load the MovieLens dataset (100k version for simplicity)\n",
    "reader = Reader(line_format='user item rating timestamp', sep='\\t')\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Build a user-item matrix\n",
    "user_item_matrix = np.zeros((trainset.n_users, trainset.n_items))\n",
    "for uid, iid, rating in trainset.all_ratings():\n",
    "    user_item_matrix[int(uid), int(iid)] = rating\n",
    "\n",
    "# Use SVD to reduce dimensionality\n",
    "svd = TruncatedSVD(n_components=50)\n",
    "atoms = svd.fit_transform(user_item_matrix.T)  # Transpose to get item embeddings\n",
    "\n",
    "# Create a signal (simulate a user's preference vector)\n",
    "user_id = 0  # Choose a user ID from the dataset\n",
    "user_ratings = user_item_matrix[user_id]\n",
    "signal = np.dot(user_ratings, atoms)  # Weighted average of rated item embeddings\n",
    "signals = signal[np.newaxis, :]  # Ensure signal has 2D shape for batch processing\n",
    "\n",
    "# Initialize Greedy MIPS parameters\n",
    "budget = 10  # Number of candidates to screen\n",
    "num_best_atoms = 10  # Top-k items to retrieve\n",
    "conditer = generate_conditer(atoms)  # Query-independent preprocessing\n",
    "\n",
    "# Run Greedy MIPS\n",
    "best_atoms, query_times, ranking_times, complexities = greedy_mips(\n",
    "    atoms=atoms,\n",
    "    signals=signals,\n",
    "    budget=budget,\n",
    "    num_best_atoms=num_best_atoms,\n",
    "    conditer=conditer,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Output results\n",
    "print(f\"Top {num_best_atoms} candidates (indices):\\n{best_atoms[0]}\")\n",
    "print(f\"Query-dependent runtime (seconds): {query_times[0]:.4f}\")\n",
    "print(f\"Candidate ranking runtime (seconds): {ranking_times[0]:.4f}\")\n",
    "print(f\"Total complexity: {complexities[0]}\")\n",
    "\n",
    "# Naive approach for validation\n",
    "inner_products = np.dot(atoms, signal)\n",
    "top_k_naive = np.argsort(inner_products)[-num_best_atoms:][::-1]\n",
    "print(f\"Top {num_best_atoms} candidates using naive approach (indices): {top_k_naive}\")\n",
    "\n",
    "# Compare results\n",
    "accuracy = len(np.intersect1d(best_atoms[0], top_k_naive)) / num_best_atoms\n",
    "print(f\"Accuracy compared to naive method: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Compute speedup ratio\n",
    "total_naive_computations = atoms.shape[0] * atoms.shape[1]\n",
    "average_complexity = complexities.mean()\n",
    "speedup_ratio = total_naive_computations / average_complexity\n",
    "print(f\"Speedup ratio: {speedup_ratio:.2f} times faster than naive computation.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movie Lens 1m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess time: 0.0\n",
      "query dependent preprocess + candidates screening: 0.0\n",
      "candidate ranking: 0.0\n",
      "Top 10 candidates (indices):\n",
      "[316 258 239 217 924 310  86 336 201 479]\n",
      "Query-dependent runtime (seconds): 0.0000\n",
      "Candidate ranking runtime (seconds): 0.0000\n",
      "Total complexity: 3430\n",
      "Top 10 candidates using naive approach (indices): [316 258 239 217 924 310  86  21 546 336]\n",
      "Accuracy compared to naive method: 80.00%\n",
      "Speedup ratio: 53.72 times faster than naive computation.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Load the MovieLens dataset (100k version for simplicity)\n",
    "reader = Reader(line_format='user item rating timestamp', sep='\\t')\n",
    "data = Dataset.load_builtin('ml-1m')\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Build a user-item matrix\n",
    "user_item_matrix = np.zeros((trainset.n_users, trainset.n_items))\n",
    "for uid, iid, rating in trainset.all_ratings():\n",
    "    user_item_matrix[int(uid), int(iid)] = rating\n",
    "\n",
    "# Use SVD to reduce dimensionality\n",
    "svd = TruncatedSVD(n_components=50)\n",
    "atoms = svd.fit_transform(user_item_matrix.T)  # Transpose to get item embeddings\n",
    "\n",
    "# Create a signal (simulate a user's preference vector)\n",
    "user_id = 0  # Choose a user ID from the dataset\n",
    "user_ratings = user_item_matrix[user_id]\n",
    "signal = np.dot(user_ratings, atoms)  # Weighted average of rated item embeddings\n",
    "signals = signal[np.newaxis, :]  # Ensure signal has 2D shape for batch processing\n",
    "\n",
    "# Initialize Greedy MIPS parameters\n",
    "budget = 10  # Number of candidates to screen\n",
    "num_best_atoms = 10  # Top-k items to retrieve\n",
    "conditer = generate_conditer(atoms)  # Query-independent preprocessing\n",
    "\n",
    "# Run Greedy MIPS\n",
    "best_atoms, query_times, ranking_times, complexities = greedy_mips(\n",
    "    atoms=atoms,\n",
    "    signals=signals,\n",
    "    budget=budget,\n",
    "    num_best_atoms=num_best_atoms,\n",
    "    conditer=conditer,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Output results\n",
    "print(f\"Top {num_best_atoms} candidates (indices):\\n{best_atoms[0]}\")\n",
    "print(f\"Query-dependent runtime (seconds): {query_times[0]:.4f}\")\n",
    "print(f\"Candidate ranking runtime (seconds): {ranking_times[0]:.4f}\")\n",
    "print(f\"Total complexity: {complexities[0]}\")\n",
    "\n",
    "# Naive approach for validation\n",
    "inner_products = np.dot(atoms, signal)\n",
    "top_k_naive = np.argsort(inner_products)[-num_best_atoms:][::-1]\n",
    "print(f\"Top {num_best_atoms} candidates using naive approach (indices): {top_k_naive}\")\n",
    "\n",
    "# Compare results\n",
    "accuracy = len(np.intersect1d(best_atoms[0], top_k_naive)) / num_best_atoms\n",
    "print(f\"Accuracy compared to naive method: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Compute speedup ratio\n",
    "total_naive_computations = atoms.shape[0] * atoms.shape[1]\n",
    "average_complexity = complexities.mean()\n",
    "speedup_ratio = total_naive_computations / average_complexity\n",
    "print(f\"Speedup ratio: {speedup_ratio:.2f} times faster than naive computation.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Netflix data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess time: 0.0\n",
      "query dependent preprocess + candidates screening: 0.0\n",
      "candidate ranking: 0.0013377666473388672\n",
      "Top 10 candidates (indices):\n",
      "[ 130  105 1151  668  509  909  218  506 1131 1014]\n",
      "Query-dependent runtime (seconds): 0.0000\n",
      "Candidate ranking runtime (seconds): 0.0013\n",
      "Total complexity: 7800\n",
      "Top 10 candidates using naive approach (indices): [1274  738   46  559  314 1171 1305  305   24  217]\n",
      "Accuracy compared to naive method: 0.00%\n",
      "Speedup ratio: 17.31 times faster than naive computation.\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed factors and biases\n",
    "movie_factors = np.load(\"data/netflix/Movie_factors_15_new.npy\")\n",
    "movie_biases = np.load(\"data/netflix/Movie_biases_15_new.npy\")\n",
    "customer_factors = np.load(\"data/netflix/Customer_factors_15_new.npy\")\n",
    "customer_biases = np.load(\"data/netflix/Customer_biases_15_new.npy\")\n",
    "global_mean = np.load(\"data/netflix/netflix_global_mean.npy\")\n",
    "\n",
    "# Use movie factors as atoms for Greedy MIPS\n",
    "atoms = movie_factors\n",
    "\n",
    "# Choose a specific user\n",
    "user_id = 0  # Replace with the desired user ID (index-based, starting at 0)\n",
    "user_factors = customer_factors[user_id]\n",
    "user_bias = customer_biases[user_id]\n",
    "\n",
    "# Construct the user preference signal\n",
    "signal = user_factors  # Optionally, add user_bias and global_mean if needed for personalization\n",
    "signals = signal[np.newaxis, :]  # Ensure signal has 2D shape for batch processing\n",
    "\n",
    "# Initialize Greedy MIPS parameters\n",
    "budget = 10  # Number of candidates to screen\n",
    "num_best_atoms = 10  # Top-k items to retrieve\n",
    "conditer = generate_conditer(atoms)  # Query-independent preprocessing\n",
    "\n",
    "# Run Greedy MIPS\n",
    "best_atoms, query_times, ranking_times, complexities = greedy_mips(\n",
    "    atoms=atoms,\n",
    "    signals=signals,\n",
    "    budget=budget,\n",
    "    num_best_atoms=num_best_atoms,\n",
    "    conditer=conditer,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Output results\n",
    "print(f\"Top {num_best_atoms} candidates (indices):\\n{best_atoms[0]}\")\n",
    "print(f\"Query-dependent runtime (seconds): {query_times[0]:.4f}\")\n",
    "print(f\"Candidate ranking runtime (seconds): {ranking_times[0]:.4f}\")\n",
    "print(f\"Total complexity: {complexities[0]}\")\n",
    "\n",
    "# Naive approach for validation\n",
    "inner_products = np.dot(atoms, signal)\n",
    "top_k_naive = np.argsort(inner_products)[-num_best_atoms:][::-1]\n",
    "print(f\"Top {num_best_atoms} candidates using naive approach (indices): {top_k_naive}\")\n",
    "\n",
    "# Compare results\n",
    "accuracy = len(np.intersect1d(best_atoms[0], top_k_naive)) / num_best_atoms\n",
    "print(f\"Accuracy compared to naive method: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Compute speedup ratio\n",
    "total_naive_computations = atoms.shape[0] * atoms.shape[1]\n",
    "average_complexity = complexities.mean()\n",
    "speedup_ratio = total_naive_computations / average_complexity\n",
    "print(f\"Speedup ratio: {speedup_ratio:.2f} times faster than naive computation.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crypto pairs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess time: 0.0\n",
      "query dependent preprocess + candidates screening: 0.031462907791137695\n",
      "candidate ranking: 0.0006921291351318359\n",
      "Top 10 candidates (indices):\n",
      "[ 13  28  51   2  58  97  35 104  77  67]\n",
      "Query-dependent runtime (seconds): 0.0315\n",
      "Candidate ranking runtime (seconds): 0.0007\n",
      "Total complexity: 3473\n",
      "Top 10 candidates using naive approach (indices): [ 13  28  51   2  58  97  35 104  57  49]\n",
      "Accuracy compared to naive method: 80.00%\n",
      "Speedup ratio: 1.51 times faster than naive computation.\n"
     ]
    }
   ],
   "source": [
    "# Load the preprocessed dataset\n",
    "dataset_path = \"data/crypto_pairs/crypto_pairs_1m_dimensions.npy\"  # Path to the saved .npy file\n",
    "crypto_data = np.load(dataset_path, allow_pickle=True)\n",
    "\n",
    "# Step 1: Use Truncated SVD to reduce dimensionality (if necessary)\n",
    "svd = TruncatedSVD(n_components=50)  # Reduce to 50 dimensions\n",
    "atoms = svd.fit_transform(crypto_data)  # The reduced dataset\n",
    "\n",
    "# Step 2: Create a query signal\n",
    "# Example: Use the first crypto pair as the query vector\n",
    "query_index = 0\n",
    "signal = atoms[query_index]  # A single crypto pair's embedding\n",
    "signals = signal[np.newaxis, :]  # Ensure signal has 2D shape for batch processing\n",
    "\n",
    "# Initialize Greedy MIPS parameters\n",
    "budget = 10  # Number of candidates to screen\n",
    "num_best_atoms = 10  # Top-k items to retrieve\n",
    "conditer = generate_conditer(atoms)  # Query-independent preprocessing\n",
    "\n",
    "# Run Greedy MIPS\n",
    "best_atoms, query_times, ranking_times, complexities = greedy_mips(\n",
    "    atoms=atoms,\n",
    "    signals=signals,\n",
    "    budget=budget,\n",
    "    num_best_atoms=num_best_atoms,\n",
    "    conditer=conditer,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Output results\n",
    "print(f\"Top {num_best_atoms} candidates (indices):\\n{best_atoms[0]}\")\n",
    "print(f\"Query-dependent runtime (seconds): {query_times[0]:.4f}\")\n",
    "print(f\"Candidate ranking runtime (seconds): {ranking_times[0]:.4f}\")\n",
    "print(f\"Total complexity: {complexities[0]}\")\n",
    "\n",
    "# Naive approach for validation\n",
    "inner_products = np.dot(atoms, signal)\n",
    "top_k_naive = np.argsort(inner_products)[-num_best_atoms:][::-1]\n",
    "print(f\"Top {num_best_atoms} candidates using naive approach (indices): {top_k_naive}\")\n",
    "\n",
    "# Compare results\n",
    "accuracy = len(np.intersect1d(best_atoms[0], top_k_naive)) / num_best_atoms\n",
    "print(f\"Accuracy compared to naive method: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Compute speedup ratio\n",
    "total_naive_computations = atoms.shape[0] * atoms.shape[1]\n",
    "average_complexity = complexities.mean()\n",
    "speedup_ratio = total_naive_computations / average_complexity\n",
    "print(f\"Speedup ratio: {speedup_ratio:.2f} times faster than naive computation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
